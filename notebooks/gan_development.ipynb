{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "import IPython.core.debugger as pdb\n",
    "from IPython.display import SVG\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_imgs(files, img_size):\n",
    "    \"\"\"Loads all facades images\n",
    "    \"\"\"\n",
    "    a_list = []\n",
    "    b_list = []\n",
    "    for fn in files:\n",
    "        img_arr = np.array(Image.open(fn))\n",
    "        a_list.append(img_arr[:, :img_size])\n",
    "        b_list.append(img_arr[:, img_size:])\n",
    "    return np.array(a_list), np.array(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/stephanrasp/repositories/CGAN-towards-CBRAIN/datasets/facades/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert K.image_data_format() == 'channels_last', 'Require channels_last!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, bn=True):\n",
    "    \"\"\"\n",
    "    Convolution block: Conv2D -> Batch norm -> LeakyReLU\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor [samples, channels/filters, height, width]\n",
    "        filters: Number of output filters\n",
    "        bn: Use batch norm\n",
    "\n",
    "    Returns:\n",
    "        x: Output tensor [samples, filters, height, width]\n",
    "    \"\"\"\n",
    "    x = Conv2D(filters, kernel_size=3, strides=2, padding='same')(x)\n",
    "    if bn:\n",
    "        x = BatchNormalization(axis=-1)(x)   # Channel axis\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample_block(x, x_down, filters, bn=True, dr=0.5):\n",
    "    \"\"\"\n",
    "    Upsampling block for Unet\n",
    "\n",
    "    Args:\n",
    "        x:\n",
    "        filters:\n",
    "        bn:\n",
    "        dr:\n",
    "\n",
    "    Returns:\n",
    "        x:\n",
    "    \"\"\"\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters, kernel_size=3, padding='same')(x)\n",
    "    if bn:\n",
    "        x = BatchNormalization(axis=-1)(x)\n",
    "    if dr > 0:\n",
    "        x = Dropout(dr)(x)\n",
    "    return concatenate([x, x_down], axis=-1)   # Concatenate along channel axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Unet_generator(img_dim, n_down, n_filters_first=64, final_activation='tanh'):\n",
    "    \"\"\"\n",
    "    Create the generator model: Unet\n",
    "    For now only 3 channels to 3 channels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define input\n",
    "    inp = Input(shape=img_dim)\n",
    "    x = inp\n",
    "\n",
    "    # Go down\n",
    "    down_list = []\n",
    "    \n",
    "    # Look at that\n",
    "    filter_list = [n_filters_first * min(8, (2 ** i)) for i in range(n_down)]\n",
    "    print(filter_list)\n",
    "    for n, n_filters in enumerate(filter_list):\n",
    "        #pdb.set_trace()\n",
    "        x = conv_block(x, n_filters)\n",
    "        down_list.append(x)\n",
    "    \n",
    "    # Go up\n",
    "    for x_down, n_filters in zip(down_list[:-1][::-1], filter_list[:-1][::-1]):\n",
    "        x = upsample_block(x, x_down, n_filters)\n",
    "\n",
    "    # Final upsampling and activation\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(3, kernel_size=3, padding='same')(x)\n",
    "    outp = Activation(final_activation)(x)\n",
    "\n",
    "    # Create and return model\n",
    "    return Model(inputs=inp, outputs=outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_PixelGAN_discriminator(img_dim, n_filters_first=64, n_layers=3):\n",
    "    \"\"\"\n",
    "    Create the discriminator model: PixelGAN\n",
    "\n",
    "    Args:\n",
    "        img_dim: Tuple of image dimensions [channels, height, width]\n",
    "        n_filters_first: Number of convolution filters in the first layer\n",
    "        n_layers: number of convolution layers including first\n",
    "\n",
    "    Returns:\n",
    "        model: Keras model\n",
    "    \"\"\"\n",
    "\n",
    "    # Get input tensor\n",
    "    inp = Input(shape=img_dim)\n",
    "\n",
    "    # First convolution layer\n",
    "    x = conv_block(inp, n_filters_first, bn=False)   # False in pytorch implentation\n",
    "\n",
    "    # Loop over next layers\n",
    "    n_filters = n_filters_first\n",
    "    for n in range(1, n_layers):\n",
    "        x = conv_block(x, n_filters)\n",
    "        n_filters = min(2**n, 8) * n_filters_first\n",
    "\n",
    "    # Final layer to scalar\n",
    "    outp = Dense(1, activation='sigmoid')(Flatten()(x))\n",
    "\n",
    "    # Create and return model\n",
    "    return Model(inputs=inp, outputs=outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 128, 256]\n"
     ]
    }
   ],
   "source": [
    "G = create_Unet_generator((256, 256, 3), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 128)  73856       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 256)  295168      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  295040      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 256)  0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 147520      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 128, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 128 0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 3)  3459        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 3)  0           conv2d_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 819,395\n",
      "Trainable params: 818,115\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1651pt\" viewBox=\"0.00 0.00 409.00 1651.00\" width=\"409pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1647)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1647 405,-1647 405,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 47177194944328 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>47177194944328</title>\n",
       "<polygon fill=\"none\" points=\"208.5,-1606.5 208.5,-1642.5 333.5,-1642.5 333.5,-1606.5 208.5,-1606.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-1620.8\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 47177194943040 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>47177194943040</title>\n",
       "<polygon fill=\"none\" points=\"209.5,-1533.5 209.5,-1569.5 332.5,-1569.5 332.5,-1533.5 209.5,-1533.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-1547.8\">conv2d_1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 47177194944328&#45;&gt;47177194943040 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>47177194944328-&gt;47177194943040</title>\n",
       "<path d=\"M271,-1606.4551C271,-1598.3828 271,-1588.6764 271,-1579.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"274.5001,-1579.5903 271,-1569.5904 267.5001,-1579.5904 274.5001,-1579.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47177194946344 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>47177194946344</title>\n",
       "<polygon fill=\"none\" points=\"141,-1460.5 141,-1496.5 401,-1496.5 401,-1460.5 141,-1460.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-1474.8\">batch_normalization_1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 47177194943040&#45;&gt;47177194946344 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>47177194943040-&gt;47177194946344</title>\n",
       "<path d=\"M271,-1533.4551C271,-1525.3828 271,-1515.6764 271,-1506.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"274.5001,-1506.5903 271,-1496.5904 267.5001,-1506.5904 274.5001,-1506.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47175789696224 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>47175789696224</title>\n",
       "<polygon fill=\"none\" points=\"187,-1387.5 187,-1423.5 355,-1423.5 355,-1387.5 187,-1387.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-1401.8\">leaky_re_lu_1: LeakyReLU</text>\n",
       "</g>\n",
       "<!-- 47177194946344&#45;&gt;47175789696224 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>47177194946344-&gt;47175789696224</title>\n",
       "<path d=\"M271,-1460.4551C271,-1452.3828 271,-1442.6764 271,-1433.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"274.5001,-1433.5903 271,-1423.5904 267.5001,-1433.5904 274.5001,-1433.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47175300282240 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>47175300282240</title>\n",
       "<polygon fill=\"none\" points=\"164.5,-1314.5 164.5,-1350.5 287.5,-1350.5 287.5,-1314.5 164.5,-1314.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226\" y=\"-1328.8\">conv2d_2: Conv2D</text>\n",
       "</g>\n",
       "<!-- 47175789696224&#45;&gt;47175300282240 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>47175789696224-&gt;47175300282240</title>\n",
       "<path d=\"M259.8764,-1387.4551C254.6299,-1378.9441 248.2636,-1368.6165 242.4724,-1359.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"245.3785,-1357.2663 237.1516,-1350.5904 239.4197,-1360.9396 245.3785,-1357.2663\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186261851496 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>47186261851496</title>\n",
       "<polygon fill=\"none\" points=\"187,-219.5 187,-255.5 355,-255.5 355,-219.5 187,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-233.8\">concatenate_2: Concatenate</text>\n",
       "</g>\n",
       "<!-- 47175789696224&#45;&gt;47186261851496 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>47175789696224-&gt;47186261851496</title>\n",
       "<path d=\"M288.5327,-1387.385C311.8067,-1361.3457 350,-1310.7995 350,-1259.5 350,-1259.5 350,-1259.5 350,-383.5 350,-336.8094 318.3613,-290.7429 295.1285,-263.2096\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"297.7324,-260.8701 288.5327,-255.615 292.4473,-265.4602 297.7324,-260.8701\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47177194855000 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>47177194855000</title>\n",
       "<polygon fill=\"none\" points=\"62,-1241.5 62,-1277.5 322,-1277.5 322,-1241.5 62,-1241.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-1255.8\">batch_normalization_2: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 47175300282240&#45;&gt;47177194855000 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>47175300282240-&gt;47177194855000</title>\n",
       "<path d=\"M217.5955,-1314.4551C213.7132,-1306.1196 209.0194,-1296.0416 204.717,-1286.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"207.8205,-1285.1776 200.4256,-1277.5904 201.475,-1288.1331 207.8205,-1285.1776\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186257101544 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>47186257101544</title>\n",
       "<polygon fill=\"none\" points=\"108,-1168.5 108,-1204.5 276,-1204.5 276,-1168.5 108,-1168.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-1182.8\">leaky_re_lu_2: LeakyReLU</text>\n",
       "</g>\n",
       "<!-- 47177194855000&#45;&gt;47186257101544 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>47177194855000-&gt;47186257101544</title>\n",
       "<path d=\"M192,-1241.4551C192,-1233.3828 192,-1223.6764 192,-1214.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"195.5001,-1214.5903 192,-1204.5904 188.5001,-1214.5904 195.5001,-1214.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186257410200 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>47186257410200</title>\n",
       "<polygon fill=\"none\" points=\"111.5,-1095.5 111.5,-1131.5 234.5,-1131.5 234.5,-1095.5 111.5,-1095.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-1109.8\">conv2d_3: Conv2D</text>\n",
       "</g>\n",
       "<!-- 47186257101544&#45;&gt;47186257410200 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>47186257101544-&gt;47186257410200</title>\n",
       "<path d=\"M187.3034,-1168.4551C185.1795,-1160.2951 182.6211,-1150.4652 180.2587,-1141.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"183.6145,-1140.3863 177.7084,-1131.5904 176.8402,-1142.1496 183.6145,-1140.3863\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186259228376 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>47186259228376</title>\n",
       "<polygon fill=\"none\" points=\"108,-584.5 108,-620.5 276,-620.5 276,-584.5 108,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-598.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 47186257101544&#45;&gt;47186259228376 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>47186257101544-&gt;47186259228376</title>\n",
       "<path d=\"M214.2656,-1168.2796C242.625,-1142.8772 288,-1093.891 288,-1040.5 288,-1040.5 288,-1040.5 288,-748.5 288,-699.6973 250.0887,-654.5749 221.9144,-627.7798\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"223.988,-624.9307 214.2656,-620.7204 219.2404,-630.0747 223.988,-624.9307\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186257501040 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>47186257501040</title>\n",
       "<polygon fill=\"none\" points=\"0,-1022.5 0,-1058.5 260,-1058.5 260,-1022.5 0,-1022.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-1036.8\">batch_normalization_3: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 47186257410200&#45;&gt;47186257501040 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>47186257410200-&gt;47186257501040</title>\n",
       "<path d=\"M162.3708,-1095.4551C157.3575,-1086.9441 151.2741,-1076.6165 145.7403,-1067.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"148.7471,-1065.4303 140.656,-1058.5904 142.7157,-1068.9831 148.7471,-1065.4303\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186258027016 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>47186258027016</title>\n",
       "<polygon fill=\"none\" points=\"46,-949.5 46,-985.5 214,-985.5 214,-949.5 46,-949.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-963.8\">leaky_re_lu_3: LeakyReLU</text>\n",
       "</g>\n",
       "<!-- 47186257501040&#45;&gt;47186258027016 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>47186257501040-&gt;47186258027016</title>\n",
       "<path d=\"M130,-1022.4551C130,-1014.3828 130,-1004.6764 130,-995.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"133.5001,-995.5903 130,-985.5904 126.5001,-995.5904 133.5001,-995.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186258228840 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>47186258228840</title>\n",
       "<polygon fill=\"none\" points=\"26.5,-876.5 26.5,-912.5 233.5,-912.5 233.5,-876.5 26.5,-876.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-890.8\">up_sampling2d_1: UpSampling2D</text>\n",
       "</g>\n",
       "<!-- 47186258027016&#45;&gt;47186258228840 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>47186258027016-&gt;47186258228840</title>\n",
       "<path d=\"M130,-949.4551C130,-941.3828 130,-931.6764 130,-922.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"133.5001,-922.5903 130,-912.5904 126.5001,-922.5904 133.5001,-922.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186258409848 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>47186258409848</title>\n",
       "<polygon fill=\"none\" points=\"68.5,-803.5 68.5,-839.5 191.5,-839.5 191.5,-803.5 68.5,-803.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-817.8\">conv2d_4: Conv2D</text>\n",
       "</g>\n",
       "<!-- 47186258228840&#45;&gt;47186258409848 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>47186258228840-&gt;47186258409848</title>\n",
       "<path d=\"M130,-876.4551C130,-868.3828 130,-858.6764 130,-849.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"133.5001,-849.5903 130,-839.5904 126.5001,-849.5904 133.5001,-849.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186259119072 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>47186259119072</title>\n",
       "<polygon fill=\"none\" points=\"0,-730.5 0,-766.5 260,-766.5 260,-730.5 0,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"130\" y=\"-744.8\">batch_normalization_4: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 47186258409848&#45;&gt;47186259119072 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>47186258409848-&gt;47186259119072</title>\n",
       "<path d=\"M130,-803.4551C130,-795.3828 130,-785.6764 130,-776.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"133.5001,-776.5903 130,-766.5904 126.5001,-776.5904 133.5001,-776.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186259226696 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>47186259226696</title>\n",
       "<polygon fill=\"none\" points=\"86.5,-657.5 86.5,-693.5 211.5,-693.5 211.5,-657.5 86.5,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-671.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 47186259119072&#45;&gt;47186259226696 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>47186259119072-&gt;47186259226696</title>\n",
       "<path d=\"M134.6966,-730.4551C136.8205,-722.2951 139.3789,-712.4652 141.7413,-703.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"145.1598,-704.1496 144.2916,-693.5904 138.3855,-702.3863 145.1598,-704.1496\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186259226696&#45;&gt;47186259228376 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>47186259226696-&gt;47186259228376</title>\n",
       "<path d=\"M159.6292,-657.4551C164.6425,-648.9441 170.7259,-638.6165 176.2597,-629.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"179.2843,-630.9831 181.344,-620.5904 173.2529,-627.4303 179.2843,-630.9831\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186259228712 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>47186259228712</title>\n",
       "<polygon fill=\"none\" points=\"88.5,-511.5 88.5,-547.5 295.5,-547.5 295.5,-511.5 88.5,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-525.8\">up_sampling2d_2: UpSampling2D</text>\n",
       "</g>\n",
       "<!-- 47186259228376&#45;&gt;47186259228712 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>47186259228376-&gt;47186259228712</title>\n",
       "<path d=\"M192,-584.4551C192,-576.3828 192,-566.6764 192,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"195.5001,-557.5903 192,-547.5904 188.5001,-557.5904 195.5001,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186259410840 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>47186259410840</title>\n",
       "<polygon fill=\"none\" points=\"130.5,-438.5 130.5,-474.5 253.5,-474.5 253.5,-438.5 130.5,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-452.8\">conv2d_5: Conv2D</text>\n",
       "</g>\n",
       "<!-- 47186259228712&#45;&gt;47186259410840 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>47186259228712-&gt;47186259410840</title>\n",
       "<path d=\"M192,-511.4551C192,-503.3828 192,-493.6764 192,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"195.5001,-484.5903 192,-474.5904 188.5001,-484.5904 195.5001,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186259521888 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>47186259521888</title>\n",
       "<polygon fill=\"none\" points=\"62,-365.5 62,-401.5 322,-401.5 322,-365.5 62,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-379.8\">batch_normalization_5: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 47186259410840&#45;&gt;47186259521888 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>47186259410840-&gt;47186259521888</title>\n",
       "<path d=\"M192,-438.4551C192,-430.3828 192,-420.6764 192,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"195.5001,-411.5903 192,-401.5904 188.5001,-411.5904 195.5001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186261478480 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>47186261478480</title>\n",
       "<polygon fill=\"none\" points=\"163.5,-292.5 163.5,-328.5 288.5,-328.5 288.5,-292.5 163.5,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226\" y=\"-306.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 47186259521888&#45;&gt;47186261478480 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>47186259521888-&gt;47186261478480</title>\n",
       "<path d=\"M200.4045,-365.4551C204.2868,-357.1196 208.9806,-347.0416 213.283,-337.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"216.525,-339.1331 217.5744,-328.5904 210.1795,-336.1776 216.525,-339.1331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186261478480&#45;&gt;47186261851496 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>47186261478480-&gt;47186261851496</title>\n",
       "<path d=\"M237.1236,-292.4551C242.3701,-283.9441 248.7364,-273.6165 254.5276,-264.2219\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"257.5803,-265.9396 259.8484,-255.5904 251.6215,-262.2663 257.5803,-265.9396\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47177194946120 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>47177194946120</title>\n",
       "<polygon fill=\"none\" points=\"167.5,-146.5 167.5,-182.5 374.5,-182.5 374.5,-146.5 167.5,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-160.8\">up_sampling2d_3: UpSampling2D</text>\n",
       "</g>\n",
       "<!-- 47186261851496&#45;&gt;47177194946120 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>47186261851496-&gt;47177194946120</title>\n",
       "<path d=\"M271,-219.4551C271,-211.3828 271,-201.6764 271,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"274.5001,-192.5903 271,-182.5904 267.5001,-192.5904 274.5001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186262097760 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>47186262097760</title>\n",
       "<polygon fill=\"none\" points=\"209.5,-73.5 209.5,-109.5 332.5,-109.5 332.5,-73.5 209.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-87.8\">conv2d_6: Conv2D</text>\n",
       "</g>\n",
       "<!-- 47177194946120&#45;&gt;47186262097760 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>47177194946120-&gt;47186262097760</title>\n",
       "<path d=\"M271,-146.4551C271,-138.3828 271,-128.6764 271,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"274.5001,-119.5903 271,-109.5904 267.5001,-119.5904 274.5001,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 47186261581216 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>47186261581216</title>\n",
       "<polygon fill=\"none\" points=\"197,-.5 197,-36.5 345,-36.5 345,-.5 197,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-14.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 47186262097760&#45;&gt;47186261581216 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>47186262097760-&gt;47186261581216</title>\n",
       "<path d=\"M271,-73.4551C271,-65.3828 271,-55.6764 271,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"274.5001,-46.5903 271,-36.5904 267.5001,-46.5904 274.5001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(G).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = create_PixelGAN_discriminator((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 131073    \n",
      "=================================================================\n",
      "Total params: 244,417\n",
      "Trainable params: 244,033\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# To make generators thread safe for multithreading\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return ThreadsafeIter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "\n",
    "class ThreadsafeIter(object):\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    https://github.com/fchollet/keras/issues/1638\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):   # Py3\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "\n",
    "def generator(a_imgs, b_imgs, bs, n_batches, shuffle=False):\n",
    "    \"\"\"First basic generator to work with facades dataset.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(n_batches):\n",
    "            x = a_imgs[i*bs:(i+1)*bs]\n",
    "            y = b_imgs[i*bs:(i+1)*bs]\n",
    "            yield x, y\n",
    "\n",
    "\n",
    "class DataGenerator(object):\n",
    "    def __init__(self, files, img_size=256, bs=4):\n",
    "        self.files = files #sorted(glob(data_dir + '*'))\n",
    "        self.a_imgs, self.b_imgs = load_all_imgs(self.files, img_size)\n",
    "        self.bs = bs\n",
    "        self.n_samples = self.a_imgs.shape[0]\n",
    "        self.n_batches = int(np.floor(self.n_samples / bs))\n",
    "        self.gen = generator(self.a_imgs, self.b_imgs, bs, self.n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_imgs(files, img_size):\n",
    "    \"\"\"Loads all facades images\n",
    "    \"\"\"\n",
    "    a_list = []\n",
    "    b_list = []\n",
    "    for fn in files:\n",
    "        img_arr = np.array(Image.open(fn))\n",
    "        a_list.append(img_arr[:, :img_size])\n",
    "        b_list.append(img_arr[:, img_size:])\n",
    "    return np.array(a_list), np.array(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_loss(y_true, y_pred):\n",
    "    return K.sum(K.abs(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    \"\"\"\n",
    "    GAN class.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize GAN object. Define attributes.\n",
    "\n",
    "        Args:\n",
    "            verbose: Verbosity level\n",
    "        \"\"\"\n",
    "        # Initialize empty networks\n",
    "        self.G = None    # Generator G(x)\n",
    "        self.D = None    # Discriminator D(x)\n",
    "        self.GD = None   # Combined D(G(x))\n",
    "\n",
    "        # Initialize the data generators\n",
    "        # Generators should be compatible to CBRAIN data generator\n",
    "        self.train_generator=None\n",
    "        self.valid_generator=None\n",
    "\n",
    "        # Define basic properties of the network\n",
    "        self.image_dim = (256, 256, 3)\n",
    "        \n",
    "        # Training information\n",
    "        # Useful if training is not done in one go\n",
    "        self.epoch_counter = 0\n",
    "        self.train_history = OrderedDict({\n",
    "            'train_discriminator_loss': [],\n",
    "            'train_generator_loss': [],\n",
    "            'valid_discriminator_loss': [],\n",
    "            'valid_generator_loss': [],\n",
    "        })\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def create_generator(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Create the generator network.\n",
    "        \"\"\"\n",
    "        self.G = create_Unet_generator(**kwargs)\n",
    "\n",
    "    def create_discriminator(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Create the discriminator network\n",
    "        \"\"\"\n",
    "        self.D = create_PixelGAN_discriminator(**kwargs)\n",
    "\n",
    "    def compile(self, loss_weights=[10, 1]):\n",
    "        \"\"\"\n",
    "        Compile the networks and create the combined network.\n",
    "        \"\"\"\n",
    "        opt = Adam(1e-3)\n",
    "        # Compile the individual models\n",
    "        self.G.compile(optimizer=opt, loss='mse')  # Loss does not matter for G\n",
    "        self.D.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "\n",
    "        # Create and compile the combined model\n",
    "        self.D.trainable = False\n",
    "        G_inp = Input(shape=(self.image_dim,))\n",
    "        G_outp = self.G(G_inp)\n",
    "        D_outp = self.D(self.G(G_inp))\n",
    "        self.GD = Model(inputs=G_inp, outputs=[G_outp, D_outp])\n",
    "        self.GD.compile(optimizer=opt, loss=[l1_loss, 'binary_crossentropy'])\n",
    "\n",
    "    def load_data_generator(self, data_dir, bs, valid_frac=0.2, **kwargs):\n",
    "        \"\"\"\n",
    "        Load the training and validation data generators for the requested\n",
    "        dataset.\n",
    "\n",
    "        Args:\n",
    "            dataset: Name of dataset\n",
    "            bs: Batch size\n",
    "        \"\"\"\n",
    "        files = sorted(glob(data_path + '*'))\n",
    "        shuffle(files)\n",
    "        split_idx = int(len(files) * valid_frac)\n",
    "        self.train_generator = DataGenerator(data_dir, files[split_idx:])\n",
    "        self.valid_generator = DataGenerator(data_dir, files[:split_idx])\n",
    "\n",
    "    def train(self, epochs):\n",
    "        \"\"\"\n",
    "        Training operation. Note that batch size is defined in the data\n",
    "        generator.\n",
    "\n",
    "        Args:\n",
    "            epochs: Number of epochs to train\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose > 0: pbar = tqdm(total=epochs * n_batches)\n",
    "        for e in range(self.epoch_counter, self.epoch_counter + epochs):\n",
    "            dl, gl = [], []\n",
    "            for b in range(n_batches):\n",
    "                if self.verbose > 0: pbar.update(1)\n",
    "                dl, gl = self.train_step(bs, dl, gl, train_D_separately,\n",
    "                                         noise_shape, n_disc)\n",
    "            self.epoch_counter += 1\n",
    "\n",
    "            # End of epoch. Compute mean generator and discriminator loss\n",
    "            self.train_history['train_discriminator_loss'].append(np.mean(dl))\n",
    "            self.train_history['train_generator_loss'].append(np.mean(gl))\n",
    "            fake = self.evaluate_test_losses(noise_shape, bs)\n",
    "\n",
    "            # Save images\n",
    "            if e % save_interval == 0:\n",
    "                self.save_images(fake)\n",
    "\n",
    "            # Update progressbar with latest losses\n",
    "            if self.verbose > 0:\n",
    "                pbar_dict = OrderedDict({k: v[-1] for k, v\n",
    "                                         in self.train_history.items()})\n",
    "                pbar.set_postfix(pbar_dict)\n",
    "        if self.verbose > 0: pbar.close()\n",
    "\n",
    "    def train_step(self, bs, dl, gl, train_D_separately, noise_shape,\n",
    "                   n_disc):\n",
    "        \"\"\"One training step. May contain several discriminator steps.\"\"\"\n",
    "\n",
    "        # STEP 1: TRAIN DISCRIMINATOR\n",
    "        self.D.trainable = True\n",
    "\n",
    "        # Get images\n",
    "        X, Y = next(self.train_generator.gen())\n",
    "\n",
    "        # Create fake images\n",
    "        fake = self.G.predict_on_batch(X)\n",
    "\n",
    "        # Concatenate real and fake images and train the discriminator\n",
    "        X_concat = np.concatenate([real, fake])\n",
    "        y_concat = np.array(\n",
    "            self.label('real') * bs + self.label('fake') * bs\n",
    "        )\n",
    "        dl.append(self.D.train_on_batch(X_concat, y_concat))\n",
    "\n",
    "\n",
    "        # STEP 2: TRAIN GENERATOR\n",
    "        self.D.trainable = False\n",
    "        gl.append(self.GD.train_on_batch())\n",
    "        return dl, gl\n",
    "\n",
    "    def evaluate_test_losses(self, noise_shape, bs):\n",
    "        \"\"\"Compute losses for test set and returns some fake images\"\"\"\n",
    "        fake = self.G.predict()\n",
    "        X_concat = np.concatenate([self.X_test, fake])\n",
    "        y_concat = np.array(\n",
    "            self.label('real') * self.n_test +\n",
    "            self.label('fake') * self.n_test\n",
    "        )\n",
    "        self.train_history['test_discriminator_loss'].append(\n",
    "            self.D.evaluate(X_concat, y_concat, batch_size=bs, verbose=0)\n",
    "        )\n",
    "        self.train_history['test_generator_loss'].append(\n",
    "            self.GD.evaluate())\n",
    "        return fake\n",
    "\n",
    "    def label(self, s):\n",
    "        \"\"\"Little helper function to return labels\"\"\"\n",
    "        assert s in ['real', 'fake'], 'Wrong string for label function.'\n",
    "        return [1] if s == 'real' else [0]\n",
    "\n",
    "    def save_images(self, fake):\n",
    "        \"\"\"Saves some fake images\"\"\"\n",
    "        s = (self.img_dir + '/' + self.exp_id + '_' +\n",
    "               'plot_epoch_{0:04d}_generated'.format(self.epoch_counter))\n",
    "        if self.dataset == 'mnist':\n",
    "            # From https://github.com/lukedeo/keras-acgan/blob/master/mnist_acgan.py\n",
    "            img = (np.concatenate(\n",
    "                [fake[i * 3:(i + 1) * 3, :, :, 0].reshape(-1, self.image_size)\n",
    "                 for i in range(3)],\n",
    "                axis=-1\n",
    "            ) * 127.5 + 127.5).astype(np.uint8)\n",
    "            Image.fromarray(img).save(s + '.png')\n",
    "        if self.dataset == 'radar':\n",
    "            np.save(s + '.npy', fake[:9])\n",
    "\n",
    "    def save_models(self):\n",
    "        \"\"\"\n",
    "        Saves models and training history\n",
    "        \"\"\"\n",
    "        s = self.model_dir + self.exp_id + '_'\n",
    "        self.G.save(s + 'G.h5')\n",
    "        self.D.save(s + 'D.h5')\n",
    "        self.GD.save(s + 'GD.h5')\n",
    "        # Save training history\n",
    "        with open(s + 'history.pkl', 'wb') as f:\n",
    "            pickle.dump(self.train_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
